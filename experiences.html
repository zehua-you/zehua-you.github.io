<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Experiences</title>
    <link rel="stylesheet" href="assets/css/experiences.css" />
    <script src="assets/js/experiences.js" defer></script>
</head>

<body>
    <!-- NAVBAR -->
    <div class="navigation-bar">
        <nav class="nav-links">
            <a href="index.html">Home</a>
            <a href="hobbies.html">Hobbies</a>
            <a href="experiences.html" class="active">Experiences</a>
            <a href="publications.html">Publications</a>
            <!-- <a href="assets/files/Zehua You CV.pdf" target="_blank">CV</a> -->
        </nav>
    </div>

    <div class="experiences-section">
        <div class="experiences-header">
            Research Experiences
        </div>

        <div class="experiences">
            <!-- Experience 1 -->
            <div class="experience-block">
                <div class="left-block">
                    <div class="experience-time">
                        Sep 2025 – Present
                    </div>
                    <div class="experience-location">
                        Swarthmore College
                    </div>
                    <div class="project-title">
                        Deepfake Perception Analysis
                    </div>
                    <div class="project-supervisor">
                        Supervised by Dr. Sukrit Venkatagiri
                    </div>
                    <div class="project-description">
                        My work on deepfake perception examines how people actually interpret and morally evaluate AI-generated media in everyday life. Rather than assuming synthetic content is judged through a simple “real vs. fake” lens, I study the intuitions people already use to reason about consent, authenticity, responsibility, and social harm as images, voices, and videos become increasingly realistic and context-dependent.
                    </div>
                    <div class="project-description">
                        Through large-scale qualitative interview analysis, I examine how people’s moral evaluations of AI-generated media change across situations, and what people treat as legitimately harmful, acceptable, or ambiguous. My goal is to connect empirical public values to the design and governance of deepfake technologies by grounding ethical and policy decisions in how people actually reason about synthetic media, not in abstract assumptions about how they ought to.
                    </div>
                </div>
                <div class="right-block">
                    <div class="project-visuals">
                        <button class="carousel-arrow carousel-arrow-left" aria-label="Previous image">&#10094;</button>
                        
                        <div class="image-carousel">
                            <img src="assets/img/deepfake_perception/deepfake_perception_1.png" alt="atlas.ti screenshot 1" />
                            <img src="assets/img/deepfake_perception/deepfake_perception_2.png" alt="atlas.ti screenshot 2" />
                        </div>

                        <button class="carousel-arrow carousel-arrow-right" aria-label="Next image">&#10095;</button>
                    </div>
                </div>
            </div>

            <!-- Experience 2 -->
            <div class="experience-block">
                <div class="left-block">
                    <div class="experience-time">
                        Jun 2025 – Aug 2025
                    </div>
                    <div class="experience-location">
                        Swarthmore College
                    </div>
                    <div class="project-title">
                        Scam Inoculation System
                    </div>
                    <div class="project-supervisor">
                        Supervised by Dr. Sukrit Venkatagiri
                    </div>
                    <div class="project-description">
                        My research on Scam Inoculation asks how people actually recognize manipulation in the moment—and what kinds of practice help them build durable judgment under pressure. Instead of treating “falling for scams” as a simple knowledge gap, the system focuses on the reasoning, confidence, and situational cues people rely on when fraud becomes conversational, personalized, and hard to classify.
                    </div>
                    <div class="project-description">
                        To study and support those real-world judgments, I engineered a LLM-based prompting pipeline that enables scammers–target simulation while maintaining safe interactions. Tested with a controlled user study, the system demonstrates that guided, indirect practice can improve scam recognition and self-efficacy—pointing toward a scalable and safer model for digital safety education that doesn’t require exposing learners to real harm.
                    </div>
                </div>
                <div class="right-block">
                    <div class="project-visuals">
                        <button class="carousel-arrow carousel-arrow-left" aria-label="Previous image">&#10094;</button>
                        
                        <div class="image-carousel">
                            <img src="assets/img/scam_innoculation_system/scam_innoculation_system_1.png" alt="scamInnoculationSystem screenshot 1"/>
                            <img src="assets/img/scam_innoculation_system/scam_innoculation_system_2.png" alt="scamInnoculationSystem screenshot 2"/>
                            <img src="assets/img/scam_innoculation_system/scam_innoculation_system_3.png" alt="scamInnoculationSystem screenshot 3"/>
                            <img src="assets/img/scam_innoculation_system/scam_innoculation_system_4.png" alt="scamInnoculationSystem screenshot 4"/>
                            <img src="assets/img/scam_innoculation_system/scam_innoculation_system_5.png" alt="scamInnoculationSystem screenshot 5"/>
                        </div>

                        <button class="carousel-arrow carousel-arrow-right" aria-label="Next image">&#10095;</button>
                    </div>
                </div>
            </div>

            <!-- Experience 3 -->
            <div class="experience-block">
                <div class="left-block">
                    <div class="experience-time">
                        Jun 2024 – Aug 2024
                    </div>
                    <div class="experience-location">
                        Swarthmore College
                    </div>
                    <div class="project-title">
                        Artificial Intelligence Toolkit (AITK)
                    </div>
                    <div class="project-supervisor">
                        Supervised by Dr. Lisa Meeden
                    </div>
                    <div class="project-description">
                        AITK grew out of a simple question: how do students form accurate intuitions about AI systems when most explanations are either too abstract to “feel real” or too large to reproduce and inspect? Rather than presenting models as black boxes with outcomes to memorize, the toolkit was designed around the idea that conceptual understanding comes from seeing learning unfold—step by step, with the assumptions and tradeoffs made visible.
                    </div>
                    <div class="project-description">
                        I developed small, fully reproducible language and embedding models embedded in interactive notebooks, alongside guided modules and visualizations that reveal training dynamics as they happen. Piloted at multiple institutions, AITK helps students connect theory to mechanism—building stronger mental models of how AI systems learn, generalize, and fail, and giving instructors a concrete way to teach modern ML without sacrificing transparency.
                    </div>
                </div>
                <div class="right-block">
                    <div class="project-visuals">
                        <button class="carousel-arrow carousel-arrow-left" aria-label="Previous image">&#10094;</button>
                        
                        <div class="image-carousel">
                            <img src="assets/img/aitk/AITK_1.png" alt="AITK screenshot 1" />
                            <img src="assets/img/aitk/AITK_2.png" alt="AITK screenshot 2" />
                            <img src="assets/img/aitk/AITK_3.png" alt="AITK screenshot 3" />
                        </div>

                        <button class="carousel-arrow carousel-arrow-right" aria-label="Next image">&#10095;</button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Internships -->
        <div class="internship-header">
            Internship Experiences
        </div>

        <div class="internships">
            <div class="internship-block">
                <div class="left-block">
                    <div class="internship-time">
                        Aug 2025 – Sept 2025
                    </div>
                    <div class="internship-location">
                        AI Research Institute, GRG Banking Co., Ltd.
                    </div>
                    <div class="project-title">
                        Multimodal Learning Algorithm Designer
                    </div>
                    <div class="project-description">
                        At GRG’s AI Research Institute, I worked on multimodal learning methods for video–text retrieval. I surveyed
                        state-of-the-art architectures (e.g., CLIP4CLIP, UCoFiA, Cap4Video), implemented a Python/PyTorch prototype
                        combining convolutional backbones with cross-modal attention, and set up a training and evaluation
                        pipeline on the MSR-VTT dataset using standard retrieval metrics such as Recall@K and median rank.
                    </div>
                </div>
                <div class="right-block">
                    <div class="project-visuals">
                        <button class="carousel-arrow carousel-arrow-left" aria-label="Previous image">&#10094;</button>
                        
                        <div class="image-carousel">
                            <img src="assets/img/grgbanking/grgbanking1.png" alt="grgbanking screenshot 1" />
                            <img src="assets/img/grgbanking/grgbanking2.png" alt="grgbanking screenshot 2" />
                        </div>

                        <button class="carousel-arrow carousel-arrow-right" aria-label="Next image">&#10095;</button>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
